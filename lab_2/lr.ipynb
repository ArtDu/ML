{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import fmin_tnc\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def net_input(theta, x):\n",
    "        return np.dot(x, theta)\n",
    "\n",
    "    def probability(self, theta, x):\n",
    "        return self.sigmoid(self.net_input(theta, x))\n",
    "\n",
    "    def cost_function(self, theta, x, y):\n",
    "        m = x.shape[0]\n",
    "        total_cost = -(1 / m) * np.sum(\n",
    "            y * np.log(self.probability(theta, x)) + (1 - y) * np.log(\n",
    "                1 - self.probability(theta, x)))\n",
    "        return total_cost\n",
    "\n",
    "    def gradient(self, theta, x, y):\n",
    "        m = x.shape[0]\n",
    "        return (1 / m) * np.dot(x.T, self.sigmoid(self.net_input(theta, x)) - y)\n",
    "\n",
    "    def fit(self, x, y, theta):\n",
    "        opt_weights = fmin_tnc(func=self.cost_function, x0=theta, fprime=self.gradient,\n",
    "                               args=(x, y.flatten()))\n",
    "        self.w_ = opt_weights[0]\n",
    "        return self\n",
    "\n",
    "    def predict(self, x, probab_threshold=0.5):\n",
    "        theta = self.w_[:, np.newaxis]\n",
    "        predicted_classes = self.probability(theta, x)\n",
    "        predicted_classes = (predicted_classes >= probab_threshold).astype(int)\n",
    "        predicted_classes = predicted_classes.flatten()\n",
    "        return predicted_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    marks_df = pd.read_csv(path)\n",
    "    return marks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"datasets/clean_tmdb.csv\")\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>gross</th>\n",
       "      <th>duration</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>title_year</th>\n",
       "      <th>director_name</th>\n",
       "      <th>actor_1_name</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_3_name</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>History</th>\n",
       "      <th>War</th>\n",
       "      <th>Music</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>nice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.107181</td>\n",
       "      <td>4.053183</td>\n",
       "      <td>16.615709</td>\n",
       "      <td>2.438596</td>\n",
       "      <td>8.999729</td>\n",
       "      <td>0.526213</td>\n",
       "      <td>-0.480838</td>\n",
       "      <td>1.148212</td>\n",
       "      <td>1.710379</td>\n",
       "      <td>1.289070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-0.348064</td>\n",
       "      <td>-0.27949</td>\n",
       "      <td>-0.20681</td>\n",
       "      <td>-0.175806</td>\n",
       "      <td>-0.200152</td>\n",
       "      <td>-0.153099</td>\n",
       "      <td>-0.084436</td>\n",
       "      <td>-0.040846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.654402</td>\n",
       "      <td>3.696258</td>\n",
       "      <td>5.396331</td>\n",
       "      <td>2.748263</td>\n",
       "      <td>3.086200</td>\n",
       "      <td>0.365076</td>\n",
       "      <td>-0.649452</td>\n",
       "      <td>-0.116096</td>\n",
       "      <td>0.826611</td>\n",
       "      <td>0.123064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-0.348064</td>\n",
       "      <td>-0.27949</td>\n",
       "      <td>-0.20681</td>\n",
       "      <td>-0.175806</td>\n",
       "      <td>-0.200152</td>\n",
       "      <td>-0.153099</td>\n",
       "      <td>-0.084436</td>\n",
       "      <td>-0.040846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.303653</td>\n",
       "      <td>2.699638</td>\n",
       "      <td>4.903054</td>\n",
       "      <td>1.819260</td>\n",
       "      <td>3.058657</td>\n",
       "      <td>1.009625</td>\n",
       "      <td>1.097744</td>\n",
       "      <td>-1.024816</td>\n",
       "      <td>-1.153637</td>\n",
       "      <td>0.384027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-0.348064</td>\n",
       "      <td>-0.27949</td>\n",
       "      <td>-0.20681</td>\n",
       "      <td>-0.175806</td>\n",
       "      <td>-0.200152</td>\n",
       "      <td>-0.153099</td>\n",
       "      <td>-0.084436</td>\n",
       "      <td>-0.040846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.426449</td>\n",
       "      <td>2.854798</td>\n",
       "      <td>6.157440</td>\n",
       "      <td>2.571310</td>\n",
       "      <td>6.817394</td>\n",
       "      <td>0.767919</td>\n",
       "      <td>-1.243964</td>\n",
       "      <td>-1.153223</td>\n",
       "      <td>0.583511</td>\n",
       "      <td>-0.632063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-0.348064</td>\n",
       "      <td>-0.27949</td>\n",
       "      <td>-0.20681</td>\n",
       "      <td>-0.175806</td>\n",
       "      <td>-0.200152</td>\n",
       "      <td>-0.153099</td>\n",
       "      <td>-0.084436</td>\n",
       "      <td>-0.040846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.672039</td>\n",
       "      <td>0.705198</td>\n",
       "      <td>1.239734</td>\n",
       "      <td>1.111448</td>\n",
       "      <td>1.161467</td>\n",
       "      <td>0.767919</td>\n",
       "      <td>-1.632068</td>\n",
       "      <td>1.416548</td>\n",
       "      <td>0.349275</td>\n",
       "      <td>1.166917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-0.348064</td>\n",
       "      <td>-0.27949</td>\n",
       "      <td>-0.20681</td>\n",
       "      <td>-0.175806</td>\n",
       "      <td>-0.200152</td>\n",
       "      <td>-0.153099</td>\n",
       "      <td>-0.084436</td>\n",
       "      <td>-0.040846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     budget  popularity      gross  duration  num_voted_users  title_year  \\\n",
       "0  5.107181    4.053183  16.615709  2.438596         8.999729    0.526213   \n",
       "1  6.654402    3.696258   5.396331  2.748263         3.086200    0.365076   \n",
       "2  5.303653    2.699638   4.903054  1.819260         3.058657    1.009625   \n",
       "3  5.426449    2.854798   6.157440  2.571310         6.817394    0.767919   \n",
       "4  5.672039    0.705198   1.239734  1.111448         1.161467    0.767919   \n",
       "\n",
       "   director_name  actor_1_name  actor_2_name  actor_3_name  ...   Romance  \\\n",
       "0      -0.480838      1.148212      1.710379      1.289070  ... -0.478229   \n",
       "1      -0.649452     -0.116096      0.826611      0.123064  ... -0.478229   \n",
       "2       1.097744     -1.024816     -1.153637      0.384027  ... -0.478229   \n",
       "3      -1.243964     -1.153223      0.583511     -0.632063  ... -0.478229   \n",
       "4      -1.632068      1.416548      0.349275      1.166917  ... -0.478229   \n",
       "\n",
       "     Horror  Mystery  History       War     Music  Documentary   Foreign  \\\n",
       "0 -0.348064 -0.27949 -0.20681 -0.175806 -0.200152    -0.153099 -0.084436   \n",
       "1 -0.348064 -0.27949 -0.20681 -0.175806 -0.200152    -0.153099 -0.084436   \n",
       "2 -0.348064 -0.27949 -0.20681 -0.175806 -0.200152    -0.153099 -0.084436   \n",
       "3 -0.348064 -0.27949 -0.20681 -0.175806 -0.200152    -0.153099 -0.084436   \n",
       "4 -0.348064 -0.27949 -0.20681 -0.175806 -0.200152    -0.153099 -0.084436   \n",
       "\n",
       "   TV Movie  nice  \n",
       "0 -0.040846     1  \n",
       "1 -0.040846     1  \n",
       "2 -0.040846     1  \n",
       "3 -0.040846     1  \n",
       "4 -0.040846     1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "y = y[:, np.newaxis]\n",
    "theta = np.zeros((X.shape[1], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My log reg:\n",
      "\n",
      "Train:\n",
      "\n",
      "accuracy: 0.7221876942200124\n",
      "report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67      1359\n",
      "           1       0.76      0.75      0.76      1859\n",
      "\n",
      "    accuracy                           0.72      3218\n",
      "   macro avg       0.72      0.72      0.72      3218\n",
      "weighted avg       0.72      0.72      0.72      3218\n",
      "\n",
      "*******************************************************\n",
      "\n",
      "Test:\n",
      "\n",
      "accuracy: 0.7419558359621451\n",
      "report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       657\n",
      "           1       0.78      0.77      0.78       928\n",
      "\n",
      "    accuracy                           0.74      1585\n",
      "   macro avg       0.73      0.74      0.73      1585\n",
      "weighted avg       0.74      0.74      0.74      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MyLogisticRegression()\n",
    "model.fit(X_train, y_train, theta)\n",
    "\n",
    "predicted_classes = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(predicted_classes, y_train.flatten())\n",
    "train_report = classification_report(predicted_classes, y_train.flatten())\n",
    "\n",
    "predicted_classes = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(predicted_classes, y_test.flatten())\n",
    "test_report = classification_report(predicted_classes, y_test.flatten())\n",
    "\n",
    "print(\"My log reg:\")\n",
    "print(\"\\nTrain:\\n\\naccuracy: {}\".format(train_accuracy))\n",
    "print(\"report:\")\n",
    "print(train_report)\n",
    "print('*'*55)\n",
    "print(\"\\nTest:\\n\\naccuracy: {}\".format(test_accuracy))\n",
    "print(\"report:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn:\n",
      "\n",
      "Train:\n",
      "\n",
      "accuracy: 0.7688004972032318\n",
      "report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73      1349\n",
      "           1       0.81      0.79      0.80      1869\n",
      "\n",
      "    accuracy                           0.77      3218\n",
      "   macro avg       0.76      0.76      0.76      3218\n",
      "weighted avg       0.77      0.77      0.77      3218\n",
      "\n",
      "*******************************************************\n",
      "\n",
      "Test:\n",
      "\n",
      "accuracy: 0.7753943217665615\n",
      "report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       660\n",
      "           1       0.81      0.80      0.81       925\n",
      "\n",
      "    accuracy                           0.78      1585\n",
      "   macro avg       0.77      0.77      0.77      1585\n",
      "weighted avg       0.78      0.78      0.78      1585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using scikit-learn\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted_classes = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(predicted_classes, y_train.flatten())\n",
    "train_report = classification_report(predicted_classes, y_train.flatten())\n",
    "\n",
    "predicted_classes = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(predicted_classes, y_test.flatten())\n",
    "test_report = classification_report(predicted_classes, y_test.flatten())\n",
    "\n",
    "print(\"Scikit-learn:\")\n",
    "print(\"\\nTrain:\\n\\naccuracy: {}\".format(train_accuracy))\n",
    "print(\"report:\")\n",
    "print(train_report)\n",
    "print('*'*55)\n",
    "print(\"\\nTest:\\n\\naccuracy: {}\".format(test_accuracy))\n",
    "print(\"report:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
